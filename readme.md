# john-connor
[100 soft GB per month](https://docs.github.com/en/pages/getting-started-with-github-pages/github-pages-limits#usage-limits) of Bot Resistance.

A shitty, AI-generated image of John:

![image](./readme/john-connor.jpg)

## WTF
My website has bots. Rats! They poke for secrets in files I maybe accidentally uploaded. They make a shit ton of requests to train AI. And I'm like, a _nobody_. Can you imagine the costs to host my website if I was _somebody_?

Github Pages offers 100 soft GB per month of bandwidth. We can use it fight the good fight: ~~Rat~~ Bot Resistance. I redirect requests for certain routes and requests with empty user-agents here. In an endless loop. Get 'er done.
